{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a454c52-c538-4d3a-a1f6-01cfd24b3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded. Shape: (38765, 3)\n",
      "Transaction column: Date, Item column: itemDescription\n",
      "Transactions: 728, Unique items: 167\n",
      "Saved HDF5: C:\\Users\\NXTWAVE\\Downloads\\Groceries Price Detection\\processed_data.h5\n",
      "Mining frequent itemsets and rules...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocess transactions\n",
    "# -------------------------------\n",
    "def preprocess_transactions(df: pd.DataFrame, tx_col: str, item_col: str):\n",
    "    df[item_col] = df[item_col].astype(str)\n",
    "    transactions = df.groupby(tx_col)[item_col].apply(list).tolist()\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    basket = mlb.fit_transform(transactions)\n",
    "    basket_df = pd.DataFrame(basket, columns=mlb.classes_)\n",
    "    return transactions, basket_df, mlb\n",
    "\n",
    "# -------------------------------\n",
    "# Run FP-Growth & generate rules\n",
    "# -------------------------------\n",
    "def run_fp_growth_and_rules(basket_df: pd.DataFrame, min_support=0.005, min_confidence=0.1):\n",
    "    bool_df = basket_df.astype(bool)\n",
    "    frequent_itemsets = fpgrowth(bool_df, min_support=min_support, use_colnames=True)\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(len)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# -------------------------------\n",
    "# Convert rules to serializable format\n",
    "# -------------------------------\n",
    "def rules_to_serializable(rules_df: pd.DataFrame):\n",
    "    rules_list = []\n",
    "    for _, row in rules_df.iterrows():\n",
    "        rules_list.append({\n",
    "            'antecedents': list(row['antecedents']),\n",
    "            'consequents': list(row['consequents']),\n",
    "            'support': row['support'],\n",
    "            'confidence': row['confidence'],\n",
    "            'lift': row['lift']\n",
    "        })\n",
    "    return rules_list\n",
    "\n",
    "# -------------------------------\n",
    "# Build recommender (Option A)\n",
    "# -------------------------------\n",
    "def build_recommender(rules_df: pd.DataFrame, basket_df: pd.DataFrame):\n",
    "    rules_list = rules_to_serializable(rules_df)\n",
    "    item_freq = basket_df.sum().sort_values(ascending=False)\n",
    "    return {\"rules\": rules_list, \"item_freq\": item_freq.tolist(), \"columns\": list(basket_df.columns)}\n",
    "\n",
    "# -------------------------------\n",
    "# Recommendation function\n",
    "# -------------------------------\n",
    "def recommend(given_items, recommender_data, top_n=5):\n",
    "    rules_list = recommender_data[\"rules\"]\n",
    "    item_freq = pd.Series(recommender_data[\"item_freq\"], index=recommender_data[\"columns\"])\n",
    "    given = set(given_items)\n",
    "    scores = {}\n",
    "    \n",
    "    # Score items based on rules\n",
    "    for r in rules_list:\n",
    "        if set(r['antecedents']).issubset(given):\n",
    "            for c in r['consequents']:\n",
    "                scores[c] = max(scores.get(c, 0), r.get('lift', 0))\n",
    "    \n",
    "    # Remove already purchased items\n",
    "    for g in list(given):\n",
    "        scores.pop(g, None)\n",
    "    \n",
    "    # If not enough recommendations, fill with frequent items\n",
    "    if len(scores) < top_n:\n",
    "        for item in item_freq.index:\n",
    "            if item not in scores and item not in given:\n",
    "                scores[item] = 0.01\n",
    "            if len(scores) >= top_n:\n",
    "                break\n",
    "\n",
    "    sorted_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [item for item, sc in sorted_items[:top_n]]\n",
    "\n",
    "# -------------------------------\n",
    "# Save pickle safely\n",
    "# -------------------------------\n",
    "def save_pickle(obj, out_path: str):\n",
    "    joblib.dump(obj, out_path)\n",
    "    print(f\"Saved PKL: {out_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Main script\n",
    "# -------------------------------\n",
    "def main():\n",
    "    INPUT_CSV = r\"C:\\Users\\NXTWAVE\\Downloads\\Groceries Price Detection\\archive (1)\\Groceries_dataset.csv\"\n",
    "    out_dir = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Groceries Price Detection\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "    \n",
    "    tx_col = 'Date'\n",
    "    item_col = 'itemDescription'\n",
    "    print(f\"Transaction column: {tx_col}, Item column: {item_col}\")\n",
    "    \n",
    "    transactions, basket_df, mlb = preprocess_transactions(df, tx_col, item_col)\n",
    "    print(f\"Transactions: {len(transactions)}, Unique items: {basket_df.shape[1]}\")\n",
    "    \n",
    "    # Save processed basket\n",
    "    processed_path = out_dir / \"processed_data.h5\"\n",
    "    basket_df.to_hdf(processed_path, key='basket', mode='w', format='table')\n",
    "    print(f\"Saved HDF5: {processed_path}\")\n",
    "    \n",
    "    print(\"Mining frequent itemsets and rules...\")\n",
    "    frequent_itemsets, rules = run_fp_growth_and_rules(basket_df)\n",
    "    print(f\"Found {len(frequent_itemsets)} frequent itemsets, {len(rules)} rules\")\n",
    "    \n",
    "    recommender = build_recommender(rules, basket_df)\n",
    "    \n",
    "    # Test recommendation\n",
    "    sample_items = ['tropical fruit', 'whole milk']\n",
    "    recs = recommend(sample_items, recommender, top_n=5)\n",
    "    print(f\"Given items: {sample_items}\")\n",
    "    print(f\"Recommended items: {recs}\")\n",
    "    \n",
    "    # Save artifacts\n",
    "    artifacts = {\n",
    "        \"mlb\": mlb,\n",
    "        \"basket_df_index\": list(basket_df.index),\n",
    "        \"frequent_itemsets\": frequent_itemsets,\n",
    "        \"rules\": rules,\n",
    "        \"recommender_data\": recommender,\n",
    "        \"raw_dataframe_head\": df.head(200)\n",
    "    }\n",
    "    pkl_path = out_dir / \"artifacts.pkl\"\n",
    "    save_pickle(artifacts, str(pkl_path))\n",
    "    \n",
    "    print(\"Done.\")\n",
    "\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d12c9-b48c-44a7-ac3d-21611d70c911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
